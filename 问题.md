### 待解决问题

1. tcp/ip 三次握手，4次挥手
2. mysql 主从、集群部署
3. linux cpu为0时，可能的原因？
4. nginx 日志格式配置
5. jwt



mark {
	background: #fff;
	color: red;
	border-bottom: 0px solid #fff;
	padding: 0.0px;
	margin: 0 0px;
}

#### 1. **10 瓶水，其中一瓶有毒，小白鼠喝完有毒的水之后，会在 24 小时后死亡，问：最少用几只小白鼠可以在 24 小时后找到具体是哪一瓶水有毒。**

四只

二进制问题。薛定谔的老鼠。

一只老鼠有两个状态，死活，对应 01。假设老鼠的个数为 A，则有 2^A>=10; A=4；

思路很简单，十瓶药编号：0,1,10,11....1001;

0 不喝。第一只老鼠喝所有个位是 1 的：13579，第二只喝十位是 1 的，第三只和百位是 1 的，第四只喝千位是 1 的。

24 小时后，看下死了的是 1，活着的是 0。按老鼠的顺序乖乖站好…… 假如第一只和第三只死了，那就是 0101，就是 5 有问题。

#### 2. **10g 文件，用 php 查看它的行数**

粗暴一点的方法 ini_set ('memory_limit','-1'); 先把当前内存限制解除了 然后直接逐行统计。时间会非常的久。

#### 3. **有 10 亿条订单数据，属于 1000 个司机的，请取出订单量前 20 的司机**

我们从设计上解决这个问题。只有一千个司机。我们可以做个简单哈希，分库分表，% 求余数。保证这一千个司机分在一千个表里，每个人有每个人的单独表。引擎用 MYSAIM，求表中数据的总数，效率飞快，遍历一千张表，求最大前二十即可。

#### 4. **根据 access.log 文件统计最近 5 秒的 qps，并以如下格式显示，01 1000（难点在 01 序号）**

```text
tail -f access.log | awk -F '[' '{print $2}' | awk '{print $1}' | uniq -c
```

#### 5. **海量日志数据，提取出某日访问百度次数最多的那个IP。**

首先是这一天，并且是访问百度的日志中的IP取出来，逐个写入到一个大文件中。注意到IP是32位的，最多有个2^32个IP。同样可以采用映射的方法，比如模1000，把整个大文件映射为1000个小文件，再找出每个小文中出现频率最大的IP（可以采用hash_map进行频率统计，然后再找出频率最大的几个）及相应的频率。然后再在这1000个最大的IP中，找出那个频率最大的IP，即为所求。


或者如下阐述（雪域之鹰）：
算法思想：分而治之+Hash
1.IP地址最多有2^32=4G种取值情况，所以不能完全加载到内存中处理； 
2.可以考虑采用“分而治之”的思想，按照IP地址的Hash(IP)%1024值，把海量IP日志分别存储到1024个小文件中。这样，每个小文件最多包含4MB个IP地址； 
3.对于每一个小文件，可以构建一个IP为key，出现次数为value的Hash map，同时记录当前出现次数最多的那个IP地址；
4.可以得到1024个小文件中的出现次数最多的IP，再依据常规的排序算法得到总体上出现次数最多的IP；

#### 6. **搜索引擎会通过日志文件把用户每次检索使用的所有检索串都记录下来，每个查询串的长度为1-255字节。**

假设目前有一千万个记录（这些查询串的重复度比较高，虽然总数是1千万，但如果除去重复后，不超过3百万个。一个查询串的重复度越高，说明查询它的用户越多，也就是越热门。），请你统计最热门的10个查询串，要求使用的内存不能超过1G。

 典型的Top K算法
